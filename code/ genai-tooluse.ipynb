{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1ce4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "bedrock_agent = boto3.client(service_name='bedrock-agent')\n",
    "\n",
    "MODEL_ID = \"amazon.nova-micro-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3481947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Your suggested travel destinations:\n",
      "1. **Kyoto, Japan**  \n",
      "   Experience traditional Japanese culture with stunning temples, beautiful gardens, and historic tea houses.\n",
      "\n",
      "2. **Banff, Canada**  \n",
      "   Enjoy breathtaking mountain scenery, outdoor activities like hiking and skiing, and charming alpine villages.\n",
      "\n",
      "3. **Santorini, Greece**  \n",
      "   Discover stunning sunsets, white-washed buildings, and crystal-clear blue waters on this iconic island in the Aegean Sea.\n"
     ]
    }
   ],
   "source": [
    "temperature = .7\n",
    "\n",
    "inference_config = {\"temperature\": temperature}\n",
    "\n",
    "system_prompts = [{\"text\": \"You are a virtual travel assistant that suggests destinations based on user preferences.\"\n",
    "                + \"Only return destination names and a brief description.\"}]\n",
    "\n",
    "messages = []\n",
    "\n",
    "message_1 = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Create a list of 3 travel destinations.\"}]\n",
    "}\n",
    "\n",
    "messages.append(message_1)\n",
    "\n",
    "response = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=messages,\n",
    "    system=system_prompts,\n",
    "    inferenceConfig=inference_config\n",
    ")\n",
    "\n",
    "def print_response(response):\n",
    "    model_response = response.get('output', {}).get('message', {}).get('content', [{}])[0].get('text', '')\n",
    "\n",
    "    print(\"✈️ Your suggested travel destinations:\")\n",
    "    print(model_response)\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849037de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Your suggested travel destinations:\n",
      "1. **Orlando, Florida** - Known for its world-famous theme parks like Disney World and Universal Studios.\n",
      "\n",
      "2. **Miami, Florida** - Famous for its vibrant nightlife, beautiful beaches, and rich cultural scene.\n",
      "\n",
      "3. **San Diego, California** - Offers beautiful beaches, the San Diego Zoo, and a mild climate year-round.\n"
     ]
    }
   ],
   "source": [
    "message_2 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Only suggest travel locations that are no more than one short flight away.\"}]\n",
    "}\n",
    "\n",
    "messages.append(message_2)\n",
    "\n",
    "response = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=messages,\n",
    "    system=system_prompts,\n",
    "    inferenceConfig=inference_config\n",
    ")\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79ac76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Your suggested travel destinations:\n",
      "1. **Orlando, Florida**  \n",
      "   Home to the magical world of Disney and Universal Studios, Orlando is a dream destination for families with kids.\n",
      "\n",
      "2. **San Diego, California**  \n",
      "   Known for its beautiful beaches, San Diego also boasts the famous San Diego Zoo and Legoland, making it a fantastic spot for family fun.\n",
      "\n",
      "3. **Nashville, Tennessee**  \n",
      "   Besides its vibrant music scene, Nashville offers family-friendly attractions like the Country Music Hall of Fame and the Adventure Science Center.\n"
     ]
    }
   ],
   "source": [
    "message_3 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Only suggest travel locations that are kids friendly.\"}]\n",
    "}\n",
    "\n",
    "messages.append(message_3)\n",
    "\n",
    "response = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=messages,\n",
    "    system=system_prompts,\n",
    "    inferenceConfig=inference_config\n",
    ")\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e551eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-east-1:120106008631:prompt/ZS24RSPIOK'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    response = bedrock_agent.create_prompt(\n",
    "        name=\"Travel-Agent-Prompt\",\n",
    "        description=\"Checks if all trip information has been provided.\",\n",
    "        variants=[\n",
    "            { \n",
    "                \"name\": \"Variant1\",\n",
    "                \"modelId\": MODEL_ID,\n",
    "                \"templateType\": \"CHAT\",\n",
    "                \"inferenceConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"temperature\": 0.4\n",
    "                    }\n",
    "                },\n",
    "                \"templateConfiguration\": { \n",
    "                    \"chat\": {\n",
    "                        'system': [ \n",
    "                            {\n",
    "                                \"text\": \"\"\"You are a travel agent evaluating trip requests for custom itineraries. \n",
    "                                Review the message carefully and answer YES or NO to the following screening questions. \n",
    "                                Be strict—if any detail is missing or unclear, answer NO.\n",
    "\n",
    "                                A) Is the destination clearly stated?\n",
    "                                B) Are the travel dates within a reasonable range (not last−minute or over a year away)?\n",
    "                                C) Does the request avoid high−risk or restricted activities (e.g., extreme sports, off−grid travel)?\n",
    "                                D) Is there any mention of a valid passport or travel documentation?\n",
    "                                E) Is there enough information to follow up with a proposed itinerary?\"\"\"\n",
    "                            }\n",
    "                        ],\n",
    "                        'messages': [{\n",
    "                            'role': 'user',\n",
    "                            'content': [ \n",
    "                                {\n",
    "                                    'text': \"Trip request: {{event_request}}\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }],\n",
    "                        'inputVariables' : [\n",
    "                            { 'name' : 'event_request'}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "        }]\n",
    "    )\n",
    "    print(\"Created!\")\n",
    "    prompt_arn = response.get(\"arn\")\n",
    "except bedrock.exceptions.ConflictException as e:\n",
    "    print(\"Already exists!\")\n",
    "    response = bedrock.list_prompts()\n",
    "    prompt = next((prompt for prompt in response['promptSummaries'] if prompt['name'] == \"TripBooker_xyz\"), None)\n",
    "    prompt_arn = prompt['arn']\n",
    "\n",
    "prompt_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cb85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "\n",
      "A) Is the destination clearly stated?\n",
      "YES. The destination is clearly stated as Italy.\n",
      "\n",
      "B) Are the travel dates within a reasonable range (not last−minute or over a year away)?\n",
      "YES. The travel dates are within a reasonable range, September 10–20 this year.\n",
      "\n",
      "C) Does the request avoid high−risk or restricted activities (e.g., extreme sports, off−grid travel)?\n",
      "YES. The request specifies a desire for a relaxing and enriching experience without any high-risk or restricted activities.\n",
      "\n",
      "D) Is there any mention of a valid passport or travel documentation?\n",
      "YES. Both travelers have valid passports.\n",
      "\n",
      "E) Is there enough information to follow up with a proposed itinerary?\n",
      "YES. There is enough information provided to start creating a proposed itinerary, including the destination, travel dates, preferred cities, and general interests in tours, cultural sites, and local restaurants.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.converse(\n",
    "    modelId=prompt_arn,\n",
    "    promptVariables={\n",
    "        'event_request': {\n",
    "            'text': \"\"\"\n",
    "                Hi there! I'm planning a trip to Italy with my partner and would love some help organizing the itinerary. We're hoping to travel between September 10–20 this year, ideally flying into Rome and spending a few days in Florence and Venice as well. We’d love recommendations on tours, cultural sites, and good local restaurants. We’re not interested in anything risky like skydiving or hiking remote trails — just want a relaxing and enriching experience. We both have valid passports. Let me know what other details you need!\n",
    "                \"\"\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b70ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client(\"lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a169fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toolUse': {'toolUseId': 'tooluse_RtmIjYAEQaihSBGLXR1Kfg', 'name': 'calculateNumbers', 'input': {'num1': 100, 'operation': 'subtract', 'num2': 60}}}\n",
      "→ Assistant triggered tool: calculateNumbers with input: {'num1': 100, 'operation': 'subtract', 'num2': 60}\n",
      "← Lambda Function output: {'result': 40.0}\n",
      "\n",
      "=== Final Assistant Response ===\n",
      "<thinking> The tool has successfully performed the subtraction operation and returned the result. I will now provide the result to the user. </thinking> \n",
      "\n",
      "The outcome of the calculation is 40.0. So, if you subtract 60 from 100, you get 40.\n"
     ]
    }
   ],
   "source": [
    "# Define the calculation tool\n",
    "math_tool = {\n",
    "    \"toolSpec\": {\n",
    "        \"name\": \"calculateNumbers\",\n",
    "        \"description\": \"Performs basic arithmetic operations\",\n",
    "        \"inputSchema\": {\n",
    "            \"json\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": {\"type\": \"string\"},\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"}\n",
    "                },\n",
    "                \"required\": [\"operation\", \"num1\", \"num2\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to trigger the Lambda calculation service\n",
    "def execute_calculation(input_data):\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName=\"math-function\",  \n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=json.dumps(input_data)\n",
    "    )\n",
    "    response_payload = response[\"Payload\"].read()\n",
    "    calculation_result = json.loads(response_payload)\n",
    "    response_body = calculation_result.get(\"body\", \"{}\")\n",
    "    return json.loads(response_body) if isinstance(response_body, str) else response_body\n",
    "\n",
    "# User's initial message\n",
    "user_input = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Please subtract 60 from 100\"}]\n",
    "}\n",
    "\n",
    "# Define system instructions\n",
    "system_instructions = [\n",
    "    {\"text\": \"\"\"\n",
    "    You are a virtual assistant capable of performing basic arithmetic operations: add, subtract, multiply, and divide.\n",
    "    If the user doesn't specify an operation, ask them for more details.\n",
    "    \"\"\"}\n",
    "]\n",
    "\n",
    "# First interaction with the model\n",
    "first_interaction = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    system=system_instructions,\n",
    "    messages=[user_input],\n",
    "    toolConfig={\n",
    "        \"tools\": [math_tool],\n",
    "        \"toolChoice\": {\"auto\": {}}\n",
    "    },\n",
    "    inferenceConfig={\"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "# Process the assistant's response to check if tool is required\n",
    "assistant_reply = first_interaction[\"output\"][\"message\"]\n",
    "message_parts = assistant_reply[\"content\"]\n",
    "tool_request_block = next((part for part in message_parts if \"toolUse\" in part), None)\n",
    "\n",
    "if not tool_request_block:\n",
    "    print(\"=== Assistant's Direct Response ===\")\n",
    "    print(message_parts[0][\"text\"])\n",
    "else:\n",
    "    tool_request = tool_request_block[\"toolUse\"]\n",
    "    tool_input_data = tool_request[\"input\"]\n",
    "    tool_id = tool_request[\"toolUseId\"]\n",
    "    print(tool_request_block)\n",
    "    print(f\"→ Assistant triggered tool: calculateNumbers with input: {tool_input_data}\")\n",
    "\n",
    "    # Execute the requested tool\n",
    "    tool_result = execute_calculation(tool_input_data)\n",
    "    print(f\"← Lambda Function output: {tool_result}\")\n",
    "\n",
    "    # Create a response based on the tool's output\n",
    "    try:\n",
    "        result_summary = f\"The outcome of the calculation is {tool_result['result']}.\"\n",
    "    except Exception as e:\n",
    "        result_summary = f\"Oops! There was an error with the calculation. ({str(e)})\"\n",
    "\n",
    "    # Generate tool result message\n",
    "    tool_response_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_id,\n",
    "                    \"content\": [{\"text\": result_summary}]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Send tool result back to the model\n",
    "    final_output = bedrock.converse(\n",
    "        modelId=MODEL_ID,\n",
    "        messages=[user_input, assistant_reply, tool_response_msg],\n",
    "        toolConfig={  \n",
    "            \"tools\": [math_tool],\n",
    "            \"toolChoice\": {\"auto\": {}}\n",
    "        },\n",
    "        inferenceConfig={\"temperature\": 0.7}\n",
    "    )\n",
    "\n",
    "    # Display the final response from the assistant\n",
    "    final_message = final_output[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(\"\\n=== Final Assistant Response ===\")\n",
    "    print(final_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
